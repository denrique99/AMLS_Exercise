{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dbcdd1c",
   "metadata": {},
   "source": [
    "# Task 1.4 – ECG - data reduction\n",
    "Reduce the data with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dabcb67",
   "metadata": {},
   "source": [
    "1.4 Data Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795d3d3",
   "metadata": {},
   "source": [
    "Step 1: Load the original raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec86ca8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full training samples: 4943\n",
      "Class distribution: Counter({0: 2910, 2: 1412, 1: 439, 3: 182})\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "# Load original split training data\n",
    "with open(\"../data/split_data.pkl\", \"rb\") as f:\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = pickle.load(f)\n",
    "\n",
    "print(f\"Full training samples: {len(X_train_split)}\")\n",
    "print(\"Class distribution:\", Counter(y_train_split))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c99fa5",
   "metadata": {},
   "source": [
    "STEP 2: Stratified Sampling (10%, 25%, 50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a4f1c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% samples: 2471\n",
      "25% samples: 1235\n",
      "10% samples: 494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def stratified_sample(X, y, percent):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=1 - percent, random_state=42)\n",
    "    for train_idx, _ in sss.split(X, y):\n",
    "        X_sample = [X[i] for i in train_idx]\n",
    "        y_sample = [y[i] for i in train_idx]\n",
    "        return X_sample, y_sample\n",
    "\n",
    "# Create reduced subsets\n",
    "X_train_50, y_train_50 = stratified_sample(X_train_split, y_train_split, 0.5)\n",
    "X_train_25, y_train_25 = stratified_sample(X_train_split, y_train_split, 0.25)\n",
    "X_train_10, y_train_10 = stratified_sample(X_train_split, y_train_split, 0.10)\n",
    "\n",
    "print(f\"50% samples: {len(X_train_50)}\")\n",
    "print(f\"25% samples: {len(X_train_25)}\")\n",
    "print(f\"10% samples: {len(X_train_10)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822c9c1",
   "metadata": {},
   "source": [
    "STEP 3: Apply STFT to Each Reduced Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "722660f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mfsafi/Desktop/AMLS Project/ehsan_AMLS_Exercise/.venv/lib/python3.9/site-packages/torch/functional.py:730: UserWarning: A window was not provided. A rectangular window will be applied,which is known to cause spectral leakage. Other windows such as torch.hann_window or torch.hamming_window are recommended to reduce spectral leakage.To suppress this warning and use a rectangular window, explicitly set `window=torch.ones(n_fft, device=<device>)`. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/SpectralOps.cpp:842.)\n",
      "  return _VF.stft(  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% shape: torch.Size([2471, 33, 1144])\n",
      "25% shape: torch.Size([1235, 33, 1140])\n",
      "10% shape: torch.Size([494, 33, 1136])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class STFTLayer(nn.Module):\n",
    "    def __init__(self, n_fft=64, hop_length=16):\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "\n",
    "    def forward(self, x):\n",
    "        stft_tensors, max_t = [], 0\n",
    "\n",
    "        # 1) compute STFTs and track longest time axis\n",
    "        for signal in x:\n",
    "            sig = torch.tensor(signal, dtype=torch.float32)\n",
    "            m = torch.stft(\n",
    "                sig,\n",
    "                n_fft=self.n_fft,\n",
    "                hop_length=self.hop_length,\n",
    "                return_complex=True\n",
    "            ).abs()\n",
    "            stft_tensors.append(m)\n",
    "            max_t = max(max_t, m.shape[1])\n",
    "\n",
    "        # 2) round up length to nearest multiple of 4 (so pooling matches)\n",
    "        if max_t % 4 != 0:\n",
    "            max_t = ((max_t + 3) // 4) * 4   # e.g. 505→508→512\n",
    "\n",
    "        # 3) right-pad every tensor to this common length\n",
    "        padded = []\n",
    "        for m in stft_tensors:\n",
    "            pad = max_t - m.shape[1]\n",
    "            padded.append(F.pad(m, (0, pad)))  # (left, right) on last dim\n",
    "\n",
    "        return torch.stack(padded)\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate STFT layer\n",
    "stft_layer = STFTLayer()\n",
    "\n",
    "# Apply STFT to reduced subsets\n",
    "X_train_50_stft = stft_layer(X_train_50)\n",
    "X_train_25_stft = stft_layer(X_train_25)\n",
    "X_train_10_stft = stft_layer(X_train_10)\n",
    "\n",
    "\n",
    "print(\"50% shape:\", X_train_50_stft.shape)\n",
    "print(\"25% shape:\", X_train_25_stft.shape)\n",
    "print(\"10% shape:\", X_train_10_stft.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db32e244",
   "metadata": {},
   "source": [
    "STEP 4: Train Model on Each Reduced Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1378f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1. Apply STFT to the validation set (if not already done):\n",
    "\n",
    "X_val_stft = stft_layer(X_val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7defe228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2. Import your DataLoader creator\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../1.1_dataset_exploration/src\")\n",
    "from dataset import create_spectrogram_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "536f1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3. Define a wrapper function to train and return accuracy\n",
    "\n",
    "from model import ECGCNN\n",
    "\n",
    "def train_on_subset(X_train_stft, y_train, X_val_stft, y_val, title=\"\"):\n",
    "    train_loader, val_loader = create_spectrogram_dataloaders(\n",
    "        X_train_stft, y_train, X_val_stft, y_val, batch_size=32, augment=False)\n",
    "\n",
    "    \n",
    "    input_shape = (1, *X_train_stft.shape[1:])  # dynamically determine input shape\n",
    "    # model = ECGCNN(input_shape=input_shape)\n",
    "    \n",
    "    model = ECGCNN()\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(5):  # keep short for quick testing\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(model(xb), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb).argmax(1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"{title} - Val Accuracy: {acc:.4f}\")\n",
    "    return model, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f38be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 % - Val Accuracy: 0.5890\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x73216 and 72960x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_50, acc_50 \u001b[38;5;241m=\u001b[39m train_on_subset(X_train_50_stft, y_train_50, X_val_stft, y_val_split, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m50 \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model_25, acc_25 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_25_stft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_25\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_stft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m25 \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model_10, acc_10 \u001b[38;5;241m=\u001b[39m train_on_subset(X_train_10_stft, y_train_10, X_val_stft, y_val_split, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10 \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 36\u001b[0m, in \u001b[0;36mtrain_on_subset\u001b[0;34m(X_train_stft, y_train, X_val_stft, y_val, title)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[1;32m     35\u001b[0m     xb, yb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device), yb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 36\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     37\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m yb)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     38\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m yb\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/AMLS Project/ehsan_AMLS_Exercise/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AMLS Project/ehsan_AMLS_Exercise/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/AMLS Project/dennis_AMLS_Exercise/AMLS_Exercise/1.4_data_reduction/../1.1_dataset_exploration/src/model.py:38\u001b[0m, in \u001b[0;36mECGCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     31\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLinear(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m64\u001b[39m),\n\u001b[1;32m     32\u001b[0m         nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m     33\u001b[0m         nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m     34\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 38\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Desktop/AMLS Project/ehsan_AMLS_Exercise/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AMLS Project/ehsan_AMLS_Exercise/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/AMLS Project/ehsan_AMLS_Exercise/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/AMLS Project/ehsan_AMLS_Exercise/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AMLS Project/ehsan_AMLS_Exercise/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/AMLS Project/ehsan_AMLS_Exercise/.venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x73216 and 72960x64)"
     ]
    }
   ],
   "source": [
    "model_50, acc_50 = train_on_subset(X_train_50_stft, y_train_50, X_val_stft, y_val_split, \"50 %\")\n",
    "model_25, acc_25 = train_on_subset(X_train_25_stft, y_train_25, X_val_stft, y_val_split, \"25 %\")\n",
    "model_10, acc_10 = train_on_subset(X_train_10_stft, y_train_10, X_val_stft, y_val_split, \"10 %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac67355",
   "metadata": {},
   "source": [
    "STEP 5: Plot Accuracy vs Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef4e5b5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# X-axis: dataset sizes\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m50\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m [\u001b[43macc_50\u001b[49m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Plot\u001b[39;00m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc_50' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# X-axis: dataset sizes\n",
    "sizes = [10, 25, 50]\n",
    "accuracies = [acc_50]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(sizes, accuracies, marker='o')\n",
    "plt.title(\"Validation Accuracy vs Reduced Dataset Size\")\n",
    "plt.xlabel(\"Training Dataset Size (%)\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.xticks(sizes)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b981b",
   "metadata": {},
   "source": [
    "STEP 6: Generate reduced.csv from the 25% model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cc5c947",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply STFT to test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_test_stft \u001b[38;5;241m=\u001b[39m stft_layer(\u001b[43mX_test_raw\u001b[49m)\n\u001b[1;32m      3\u001b[0m X_test_stft \u001b[38;5;241m=\u001b[39m X_test_stft\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Predict using 25% model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test_raw' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply STFT to test data\n",
    "X_test_stft = stft_layer(X_test_raw)\n",
    "X_test_stft = X_test_stft.unsqueeze(1).to(device)\n",
    "\n",
    "# Predict using 25% model\n",
    "model_25.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model_25(X_test_stft).argmax(dim=1).cpu().numpy()\n",
    "\n",
    "# Save to reduced.csv\n",
    "pd.DataFrame(preds, columns=[\"label\"]).to_csv(\"reduced.csv\", index=False)\n",
    "print(\"✅ reduced.csv created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
